{{- if .Values.rules.thanos.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ include "monitoring-extras.fullname" . }}-thanos
  labels:
    {{- include "monitoring-extras.labels" . | nindent 4 }}
spec:
  groups:
  - name: thanos-compact
    rules:
      - alert: ThanosCompactMultipleRunning
        annotations:
          description: {{ "No more than one Thanos Compact instance should be running at once. There are {{$value}} instances running." | quote }}
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactmultiplerunning
          summary: Thanos Compact has multiple instances running.
        expr: sum by (job) (up{job=~".*thanos-compact.*"}) > 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosCompactHalted
        annotations:
          description: {{ "Thanos Compact {{$labels.job}} has failed to run and now is halted." | quote }}
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthalted
          summary: Thanos Compact has failed to run ans is now halted.
        expr: thanos_compact_halted{job=~".*thanos-compact.*"} == 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosCompactHighCompactionFailures
        annotations:
          description: {{ "Thanos Compact {{$labels.job}} is failing to execute {{$value | humanize}}% of compactions." | quote }}
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthighcompactionfailures
          summary: Thanos Compact is failing to execute compactions.
        expr: |
          (
            sum by (job) (rate(thanos_compact_group_compactions_failures_total{job=~".*thanos-compact.*"}[5m]))
          /
            sum by (job) (rate(thanos_compact_group_compactions_total{job=~".*thanos-compact.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosCompactBucketHighOperationFailures
        annotations:
          description: {{ "Thanos Compact {{$labels.job}} Bucket is failing to execute {{$value | humanize}}% of operations." | quote }}
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactbuckethighoperationfailures
          summary: Thanos Compact Bucket is having a high number of operation failures.
        expr: |
          (
            sum by (job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-compact.*"}[5m]))
          /
            sum by (job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-compact.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosCompactHasNotRun
        annotations:
          description: {{ "Thanos Compact {{$labels.job}} has not uploaded anything for 24 hours." | quote }}
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthasnotrun
          summary: Thanos Compact has not uploaded anything for last 24 hours.
        expr: (time() - max by (job) (max_over_time(thanos_objstore_bucket_last_successful_upload_time{job=~".*thanos-compact.*"}[24h])))
          / 60 / 60 > 24
        labels:
          severity: warning
  - name: thanos-rule
    rules:
    - alert: ThanosRuleQueueIsDroppingAlerts
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} is failing to queue alerts." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulequeueisdroppingalerts
        summary: Thanos Rule is failing to queue alerts.
      expr: |
        sum by (job, instance) (rate(thanos_alert_queue_alerts_dropped_total{job=~".*thanos-rule.*"}[5m])) > 0
      for: 5m
      labels:
        severity: critical
    - alert: ThanosRuleSenderIsFailingAlerts
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} is failing to send alerts to alertmanager." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulesenderisfailingalerts
        summary: Thanos Rule is failing to send alerts to alertmanager.
      expr: |
        sum by (job, instance) (rate(thanos_alert_sender_alerts_dropped_total{job=~".*thanos-rule.*"}[5m])) > 0
      for: 5m
      labels:
        severity: critical
    - alert: ThanosRuleHighRuleEvaluationFailures
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} is failing to evaluate rules." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulehighruleevaluationfailures
        summary: Thanos Rule is failing to evaluate rules.
      expr: |
        (
          sum by (job, instance) (rate(prometheus_rule_evaluation_failures_total{job=~".*thanos-rule.*"}[5m]))
        /
          sum by (job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-rule.*"}[5m]))
        * 100 > 5
        )
      for: 5m
      labels:
        severity: critical
    - alert: ThanosRuleHighRuleEvaluationWarnings
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} has high number of evaluation warnings." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulehighruleevaluationwarnings
        summary: Thanos Rule has high number of evaluation warnings.
      expr: |
        sum by (job, instance) (rate(thanos_rule_evaluation_with_warnings_total{job=~".*thanos-rule.*"}[5m])) > 0
      for: 15m
      labels:
        severity: info
    - alert: ThanosRuleRuleEvaluationLatencyHigh
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} has higher evaluation latency than interval for {{$labels.rule_group}}." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosruleruleevaluationlatencyhigh
        summary: Thanos Rule has high rule evaluation latency.
      expr: |
        (
          sum by (job, instance, rule_group) (prometheus_rule_group_last_duration_seconds{job=~".*thanos-rule.*"})
        >
          sum by (job, instance, rule_group) (prometheus_rule_group_interval_seconds{job=~".*thanos-rule.*"})
        )
      for: 5m
      labels:
        severity: warning
    - alert: ThanosRuleGrpcErrorRate
      annotations:
        description: {{ "Thanos Rule {{$labels.job}} is failing to handle {{$value | humanize}}% of requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulegrpcerrorrate
        summary: Thanos Rule is failing to handle grpc requests.
      expr: |
        (
          sum by (job, instance) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-rule.*"}[5m]))
        /
          sum by (job, instance) (rate(grpc_server_started_total{job=~".*thanos-rule.*"}[5m]))
        * 100 > 5
        )
      for: 5m
      labels:
        severity: warning
    - alert: ThanosRuleConfigReloadFailure
      annotations:
        description: {{ "Thanos Rule {{$labels.job}} has not been able to reload its configuration." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosruleconfigreloadfailure
        summary: Thanos Rule has not been able to reload configuration.
      expr: avg by (job, instance) (thanos_rule_config_last_reload_successful{job=~".*thanos-rule.*"})
        != 1
      for: 5m
      labels:
        severity: info
    - alert: ThanosRuleQueryHighDNSFailures
      annotations:
        description: {{ "Thanos Rule {{$labels.job}} has {{$value | humanize}}% of failing DNS queries for query endpoints." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulequeryhighdnsfailures
        summary: Thanos Rule is having high number of DNS failures.
      expr: |
        (
          sum by (job, instance) (rate(thanos_rule_query_apis_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
        /
          sum by (job, instance) (rate(thanos_rule_query_apis_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
        * 100 > 1
        )
      for: 15m
      labels:
        severity: warning
    - alert: ThanosRuleAlertmanagerHighDNSFailures
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} has {{$value | humanize}}% of failing DNS queries for Alertmanager endpoints." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulealertmanagerhighdnsfailures
        summary: Thanos Rule is having high number of DNS failures.
      expr: |
        (
          sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
        /
          sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
        * 100 > 1
        )
      for: 15m
      labels:
        severity: warning
    - alert: ThanosRuleNoEvaluationFor10Intervals
      annotations:
        description: {{ "Thanos Rule {{$labels.job}} has {{$value | humanize}}% rule groups that did not evaluate for at least 10x of their expected interval." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulenoevaluationfor10intervals
        summary: Thanos Rule has rule groups that did not evaluate for 10 intervals.
      expr: |
        time() -  max by (job, instance, group) (prometheus_rule_group_last_evaluation_timestamp_seconds{job=~".*thanos-rule.*"})
        >
        10 * max by (job, instance, group) (prometheus_rule_group_interval_seconds{job=~".*thanos-rule.*"})
      for: 5m
      labels:
        severity: info
    - alert: ThanosNoRuleEvaluations
      annotations:
        description: {{ "Thanos Rule {{$labels.instance}} did not perform any rule evaluations in the past 10 minutes." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosnoruleevaluations
        summary: Thanos Rule did not perform any rule evaluations.
      expr: |
        sum by (job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-rule.*"}[5m])) <= 0
          and
        sum by (job, instance) (thanos_rule_loaded_rules{job=~".*thanos-rule.*"}) > 0
      for: 5m
      labels:
        severity: critical
  - name: thanos-store
    rules:
    - alert: ThanosStoreGrpcErrorRate
      annotations:
        description: {{ "Thanos Store {{$labels.job}} is failing to handle {{$value | humanize}}% of requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoregrpcerrorrate
        summary: Thanos Store is failing to handle qrpcd requests.
      expr: |
        (
          sum by (job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-store.*"}[5m]))
        /
          sum by (job) (rate(grpc_server_started_total{job=~".*thanos-store.*"}[5m]))
        * 100 > 5
        )
      for: 5m
      labels:
        severity: warning
    - alert: ThanosStoreSeriesGateLatencyHigh
      annotations:
        description: {{ "Thanos Store {{$labels.job}} has a 99th percentile latency of {{$value}} seconds for store series gate requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreseriesgatelatencyhigh
        summary: Thanos Store has high latency for store series gate requests.
      expr: |
        (
          histogram_quantile(0.99, sum by (job, le) (rate(thanos_bucket_store_series_gate_duration_seconds_bucket{job=~".*thanos-store.*"}[5m]))) > 2
        and
          sum by (job) (rate(thanos_bucket_store_series_gate_duration_seconds_count{job=~".*thanos-store.*"}[5m])) > 0
        )
      for: 10m
      labels:
        severity: warning
    - alert: ThanosStoreBucketHighOperationFailures
      annotations:
        description: {{ "Thanos Store {{$labels.job}} Bucket is failing to execute {{$value | humanize}}% of operations." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstorebuckethighoperationfailures
        summary: Thanos Store Bucket is failing to execute operations.
      expr: |
        (
          sum by (job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-store.*"}[5m]))
        /
          sum by (job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-store.*"}[5m]))
        * 100 > 5
        )
      for: 15m
      labels:
        severity: warning
    - alert: ThanosStoreObjstoreOperationLatencyHigh
      annotations:
        description: {{ "Thanos Store {{$labels.job}} Bucket has a 99th percentile latency of {{$value}} seconds for the bucket operations." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreobjstoreoperationlatencyhigh
        summary: Thanos Store is having high latency for bucket operations.
      expr: |
        (
          histogram_quantile(0.99, sum by (job, le) (rate(thanos_objstore_bucket_operation_duration_seconds_bucket{job=~".*thanos-store.*"}[5m]))) > 2
        and
          sum by (job) (rate(thanos_objstore_bucket_operation_duration_seconds_count{job=~".*thanos-store.*"}[5m])) > 0
        )
      for: 10m
      labels:
        severity: warning
  - name: thanos-sidecar
    rules:
    - alert: ThanosSidecarPrometheusDown
      annotations:
        description: {{ "Thanos Sidecar {{$labels.instance}} cannot connect to Prometheus." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanossidecarprometheusdown
        summary: Thanos Sidecar cannot connect to Prometheus
      expr: |
        thanos_sidecar_prometheus_up{job=~".*thanos-sidecar.*"} == 0
      for: 5m
      labels:
        severity: critical
    - alert: ThanosSidecarBucketOperationsFailed
      annotations:
        description: {{ "Thanos Sidecar {{$labels.instance}} bucket operations are failing" | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanossidecarbucketoperationsfailed
        summary: Thanos Sidecar bucket operations are failing
      expr: |
        sum by (job, instance) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-sidecar.*"}[5m])) > 0
      for: 5m
      labels:
        severity: critical
    - alert: ThanosSidecarUnhealthy
      annotations:
        description: {{ "Thanos Sidecar {{$labels.instance}} is unhealthy for more than {{$value}} seconds." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanossidecarunhealthy
        summary: Thanos Sidecar is unhealthy.
      expr: |
        time() - max by (job, instance) (thanos_sidecar_last_heartbeat_success_time_seconds{job=~".*thanos-sidecar.*"}) >= 240
      for: 5m
      labels:
        severity: critical
  - name: thanos-query
    rules:
    - alert: ThanosQueryHttpRequestQueryErrorRateHigh
      annotations:
        description: {{ "Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}% of query requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryerrorratehigh
        summary: Thanos Query is failing to handle requests.
      expr: |
        (
          sum by (job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query.*", handler="query"}[5m]))
        /
          sum by (job) (rate(http_requests_total{job=~".*thanos-query.*", handler="query"}[5m]))
        ) * 100 > 5
      for: 5m
      labels:
        severity: critical
    - alert: ThanosQueryHttpRequestQueryRangeErrorRateHigh
      annotations:
        description: {{ "Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}% of query_range requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryrangeerrorratehigh
        summary: Thanos Query is failing to handle requests.
      expr: |
        (
          sum by (job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query.*", handler="query_range"}[5m]))
        /
          sum by (job) (rate(http_requests_total{job=~".*thanos-query.*", handler="query_range"}[5m]))
        ) * 100 > 5
      for: 5m
      labels:
        severity: critical
    - alert: ThanosQueryGrpcServerErrorRate
      annotations:
        description: {{ "Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}% of requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcservererrorrate
        summary: Thanos Query is failing to handle requests.
      expr: |
        (
          sum by (job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-query.*"}[5m]))
        /
          sum by (job) (rate(grpc_server_started_total{job=~".*thanos-query.*"}[5m]))
        * 100 > 5
        )
      for: 5m
      labels:
        severity: warning
    - alert: ThanosQueryGrpcClientErrorRate
      annotations:
        description: {{ "Thanos Query {{$labels.job}} is failing to send {{$value | humanize}}% of requests." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcclienterrorrate
        summary: Thanos Query is failing to send requests.
      expr: |
        (
          sum by (job) (rate(grpc_client_handled_total{grpc_code!="OK", job=~".*thanos-query.*"}[5m]))
        /
          sum by (job) (rate(grpc_client_started_total{job=~".*thanos-query.*"}[5m]))
        ) * 100 > 5
      for: 5m
      labels:
        severity: warning
    - alert: ThanosQueryHighDNSFailures
      annotations:
        description: {{ "Thanos Query {{$labels.job}} have {{$value | humanize}}% of failing DNS queries for store endpoints." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhighdnsfailures
        summary: Thanos Query is having high number of DNS failures.
      expr: |
        (
          sum by (job) (rate(thanos_query_store_apis_dns_failures_total{job=~".*thanos-query.*"}[5m]))
        /
          sum by (job) (rate(thanos_query_store_apis_dns_lookups_total{job=~".*thanos-query.*"}[5m]))
        ) * 100 > 1
      for: 15m
      labels:
        severity: warning
    - alert: ThanosQueryInstantLatencyHigh
      annotations:
        description: {{ "Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}} seconds for instant queries." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryinstantlatencyhigh
        summary: Thanos Query has high latency for queries.
      expr: |
        (
          histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query"}[5m]))) > 40
        and
          sum by (job) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query"}[5m])) > 0
        )
      for: 10m
      labels:
        severity: critical
    - alert: ThanosQueryRangeLatencyHigh
      annotations:
        description: {{ "Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}} seconds for range queries." | quote }}
        runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryrangelatencyhigh
        summary: Thanos Query has high latency for queries.
      expr: |
        (
          histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query.*", handler="query_range"}[5m]))) > 90
        and
          sum by (job) (rate(http_request_duration_seconds_count{job=~".*thanos-query.*", handler="query_range"}[5m])) > 0
        )
      for: 10m
      labels:
        severity: critical
{{- end }}